import os
import re
import pickle
import numpy as np
from pathlib import Path
from dotenv import load_dotenv
from rank_bm25 import BM25Okapi
from langchain_together import Together
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.prompts import PromptTemplate

# ========== C·∫§U H√åNH ==========
load_dotenv()
BASE_DIR = Path(__file__).resolve().parent
STORAGE_DIR = BASE_DIR / "storage"

# T·∫£i m√¥ h√¨nh
embeddings = HuggingFaceEmbeddings(model_name="dangvantuan/vietnamese-embedding")
vector_store = FAISS.load_local(
    STORAGE_DIR / "vector_store", 
    embeddings, 
    allow_dangerous_deserialization=True
)

# Kh·ªüi t·∫°o LLM
llm = Together(
    model="deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
    api_key=os.getenv("TOGETHER_API_KEY"),
    temperature=0.2,
    max_tokens=1024,
    top_k=3
)

# T·∫£i d·ªØ li·ªáu FAQs
with open(STORAGE_DIR / "faqs.pkl", "rb") as f:
    faqs = pickle.load(f)

# T·∫£i BM25 indexes
with open(STORAGE_DIR / "bm25_keywords.pkl", "rb") as f:
    bm25_keywords = pickle.load(f)

with open(STORAGE_DIR / "bm25_questions.pkl", "rb") as f:
    bm25_questions = pickle.load(f)

# ========== TI·ªÜN √çCH ==========
def print_colored(text, color):
    """In m√†u cho terminal"""
    colors = {
        "red": "\033[91m",
        "green": "\033[92m",
        "yellow": "\033[93m",
        "blue": "\033[94m",
        "purple": "\033[95m",
        "cyan": "\033[96m",
        "white": "\033[97m",
        "end": "\033[0m"
    }
    print(f"{colors.get(color, '')}{text}{colors['end']}")

# ========== H√ÄM CH·ª®C NƒÇNG CH√çNH ==========
def extract_keywords(question: str) -> list:
    """Tr√≠ch xu·∫•t t·ª´ kh√≥a t·ª´ c√¢u h·ªèi d√πng LLM"""
    prompt = f"""
    B·∫†N L√Ä H·ªÜ TH·ªêNG TR√çCH XU·∫§T T·ª™ KH√ìA. H√£y tr√≠ch xu·∫•t c√°c t·ª´ kh√≥a quan tr·ªçng t·ª´ c√¢u h·ªèi sau.
    CH·ªà TR·∫¢ L·ªúI B·∫∞NG DANH S√ÅCH T·ª™ KH√ìA PH√ÇN C√ÅCH B·∫∞NG D·∫§U PH·∫®Y.
    
    C√ÇU H·ªéI: {question}
    T·ª™ KH√ìA:
    """
    response = llm.invoke(prompt).strip()
    
    # L√†m s·∫°ch k·∫øt qu·∫£
    keywords = []
    for kw in re.split(r'[,;|.\n]+', response):
        clean_kw = kw.strip()
        if clean_kw and len(clean_kw) > 1:  # Lo·∫°i b·ªè t·ª´ ƒë∆°n l·∫ª
            keywords.append(clean_kw.lower())
    
    print_colored(f"\nüîë T·ª´ kh√≥a tr√≠ch xu·∫•t: {', '.join(keywords)}", "yellow")
    return keywords

def hybrid_search(question: str, keywords: list, top_k: int = 5) -> dict:
    """
    Th·ª±c hi·ªán hybrid search:
    - 30% keyword search (FAQs)
    - 70% vector search (Markdown)
    """
    # ===== 1. T√åM KI·∫æM KEYWORD-BASED (FAQs) =====
    # T√¨m b·∫±ng keywords
    tokenized_keywords = " ".join(keywords).split()
    keyword_scores = bm25_keywords.get_scores(tokenized_keywords)
    
    # T√¨m b·∫±ng c√¢u h·ªèi t∆∞∆°ng t·ª±
    tokenized_question = question.lower().split()
    question_scores = bm25_questions.get_scores(tokenized_question)
    
    # K·∫øt h·ª£p ƒëi·ªÉm s·ªë
    combined_scores = (np.array(keyword_scores) * 0.6 + (np.array(question_scores) * 0.4))
    
    # L·∫•y top k·∫øt qu·∫£
    top_indices = np.argsort(combined_scores)[-top_k:][::-1]
    faq_results = []
    for idx in top_indices:
        if combined_scores[idx] > 0:
            faq = faqs[idx]
            faq_results.append({
                "question": faq["question"],
                "answer": faq["answer"],
                "keywords": ", ".join(faq["keywords"]),
                "score": float(combined_scores[idx])
            })
    
    # ===== 2. T√åM KI·∫æM VECTOR-BASED (MARKDOWN) =====
    vector_results = []
    docs = vector_store.similarity_search_with_score(question, k=top_k)
    for doc, score in docs:
        content = doc.page_content
        # C·∫Øt ng·∫Øn n·ªôi dung ƒë·ªÉ hi·ªÉn th·ªã
        if len(content) > 500:
            content = content[:250] + " ... " + content[-250:]
            
        vector_results.append({
            "source": doc.metadata.get("source", "Unknown"),
            "content": content,
            "score": float(score)
        })
    
    # ===== 3. K·∫æT H·ª¢P K·∫æT QU·∫¢ =====
    # Chu·∫©n h√≥a ƒëi·ªÉm s·ªë
    max_faq_score = max([r["score"] for r in faq_results], default=1)
    max_vector_score = max([r["score"] for r in vector_results], default=1)
    
    combined_results = []
    for res in faq_results:
        combined_results.append({
            "type": "FAQ",
            "content": f"Q: {res['question']}\nA: {res['answer']}",
            "keywords": res["keywords"],
            "adjusted_score": (res["score"] / max_faq_score) * 0.3 if max_faq_score > 0 else 0
        })
    
    for res in vector_results:
        combined_results.append({
            "type": "MARKDOWN",
            "source": res["source"],
            "content": res["content"],
            "adjusted_score": (res["score"] / max_vector_score) * 0.7 if max_vector_score > 0 else 0
        })
    
    # S·∫Øp x·∫øp theo ƒëi·ªÉm t·ªïng h·ª£p
    combined_results.sort(key=lambda x: x["adjusted_score"], reverse=True)
    
    return {
        "faq_results": faq_results,
        "vector_results": vector_results,
        "combined_results": combined_results
    }

def generate_answer(question: str, context: str) -> str:
    """T·∫°o c√¢u tr·∫£ l·ªùi t·ª´ ng·ªØ c·∫£nh s·ª≠ d·ª•ng LLM"""
    template = """
    B·∫†N L√Ä TR·ª¢ L√ù ·∫¢O CH√çNH TH·ª®C C·ª¶A ƒê·∫†I H·ªåC B√ÅCH KHOA TH√ÄNH PH·ªê H·ªí CH√ç MINH (HCMUT).

## NGUY√äN T·∫ÆC HO·∫†T ƒê·ªòNG C·ªêT L√ïI:
1. **Ng√¥n ng·ªØ v√† phong c√°ch**: Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v·ªõi gi·ªçng ƒëi·ªáu trang tr·ªçng, chuy√™n nghi·ªáp nh∆∞ng th√¢n thi·ªán
2. **ƒê·ªô ch√≠nh x√°c**: Ch·ªâ cung c·∫•p th√¥ng tin c√≥ trong c∆° s·ªü d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p
3. **T√≠nh s√∫c t√≠ch**: C√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn, c√≥ c·∫•u tr√∫c r√µ r√†ng, ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ
4. **Ph·∫°m vi h·ªó tr·ª£**: Ch·ªâ tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn HCMUT

## C√ÅCH X·ª¨ L√ù C√ÇU H·ªéI:

### C√¢u h·ªèi li√™n quan ƒë·∫øn HCMUT:
- **C√≥ th√¥ng tin**: Tr·∫£ l·ªùi tr·ª±c ti·∫øp d·ª±a tr√™n d·ªØ li·ªáu
- **Kh√¥ng c√≥ th√¥ng tin**: "T√¥i kh√¥ng c√≥ th√¥ng tin v·ªÅ v·∫•n ƒë·ªÅ n√†y trong c∆° s·ªü d·ªØ li·ªáu hi·ªán t·∫°i. Qu√Ω ph·ª• huynh/ h·ªçc sinh/ sinh vi√™n c√≥ th·ªÉ li√™n h·ªá tr·ª±c ti·∫øp v·ªõi c√°c ph√≤ng ban li√™n quan c·ªßa tr∆∞·ªùng ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£."

### C√¢u h·ªèi ngo√†i ph·∫°m vi:
"T√¥i ch·ªâ h·ªó tr·ª£ c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn ƒê·∫°i h·ªçc B√°ch Khoa TPHCM. Qu√Ω ph·ª• huynh/ h·ªçc sinh/ sinh vi√™n c√≥ th·ªÉ h·ªèi v·ªÅ:
- Th√¥ng tin tuy·ªÉn sinh v√† ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o
- Ho·∫°t ƒë·ªông nghi√™n c·ª©u v√† h·ª£p t√°c
- D·ªãch v·ª• sinh vi√™n v√† c∆° s·ªü v·∫≠t ch·∫•t
- C√°c s·ª± ki·ªán v√† tin t·ª©c c·ªßa tr∆∞·ªùng"

## H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
- S·ª≠ d·ª•ng c·∫•u tr√∫c: **C√¢u tr·∫£ l·ªùi ch√≠nh** ‚Üí **Th√¥ng tin b·ªï sung** (n·∫øu c√≥) ‚Üí **H∆∞·ªõng d·∫´n ti·∫øp theo** (n·∫øu c·∫ßn)
- V·ªõi c√¢u h·ªèi ph·ª©c t·∫°p: Chia nh·ªè th√†nh c√°c ƒëi·ªÉm r√µ r√†ng
- Lu√¥n k·∫øt th√∫c b·∫±ng c√°ch h·ªèi c√≥ c·∫ßn h·ªó tr·ª£ th√™m g√¨ kh√°c kh√¥ng
- Tr√°nh s·ª≠ d·ª•ng t·ª´ ng·ªØ m∆° h·ªì ho·∫∑c kh√¥ng r√µ r√†ng
- Kh√¥ng s·ª≠ d·ª•ng t·ª´ ng·ªØ qu√° k·ªπ thu·∫≠t ho·∫∑c h·ªçc thu·∫≠t tr·ª´ khi c·∫ßn thi·∫øt
- Kh√¥ng ƒë∆∞a ra √Ω ki·∫øn c√° nh√¢n ho·∫∑c suy ƒëo√°n
-  Kh√¥ng s·ª≠ d·ª•ng t·ª´ ng·ªØ qu√° th√¢n m·∫≠t ho·∫∑c kh√¥ng ph√π h·ª£p v·ªõi m√¥i tr∆∞·ªùng h·ªçc thu·∫≠t


## TH√îNG TIN THAM KH·∫¢O:
{context}

## C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG:
{question}

## C√ÇU TR·∫¢ L·ªúI:
    """
    prompt = PromptTemplate.from_template(template)
    formatted_prompt = prompt.format(context=context, question=question)
    
    return llm.invoke(formatted_prompt)

# ========== GIAO DI·ªÜN CH√çNH ==========
def main():
    print_colored("\n" + "=" * 50, "cyan")
    print_colored("H·ªÜ TH·ªêNG CHATBOT TR∆Ø·ªúNG ƒê·∫†I H·ªåC B√ÅCH KHOA TPHCM", "cyan")
    print_colored("=" * 50, "cyan")
    
    while True:
        try:
            question = input("\nü§ñ B·∫°n: ")
            if question.lower() in ["exit", "quit", "tho√°t"]:
                break
                
            # B∆∞·ªõc 1: Tr√≠ch xu·∫•t t·ª´ kh√≥a
            keywords = extract_keywords(question)
            
            # B∆∞·ªõc 2: Hybrid search
            results = hybrid_search(question, keywords)
            
            # In k·∫øt qu·∫£ chi ti·∫øt
            print_colored("\n=== K·∫æT QU·∫¢ T√åM KI·∫æM FAQs ===", "green")
            for i, res in enumerate(results["faq_results"]):
                print_colored(f"\nFAQ #{i+1} (Score: {res['score']:.4f})", "yellow")
                print(f"Q: {res['question']}")
                print(f"A: {res['answer'][:150]}...")
                print(f"Keywords: {res['keywords']}")
            
            print_colored("\n=== K·∫æT QU·∫¢ T√åM KI·∫æM MARKDOWN ===", "green")
            for i, res in enumerate(results["vector_results"]):
                print_colored(f"\nDocument #{i+1} (Score: {res['score']:.4f})", "yellow")
                print(f"Source: {res['source']}")
                print(f"Content: {res['content']}")
            
            # T·∫°o ng·ªØ c·∫£nh t·ª´ top 5 k·∫øt qu·∫£ k·∫øt h·ª£p
            context = ""
            for i, res in enumerate(results["combined_results"][:5]):
                context += f"\n\n[{i+1}] {res['type']} (Score: {res['adjusted_score']:.4f}):\n"
                
                if res["type"] == "FAQ":
                    context += res["content"]
                else:
                    context += f"Source: {res['source']}\n{res['content']}"
            
            # B∆∞·ªõc 3: T·∫°o c√¢u tr·∫£ l·ªùi
            answer = generate_answer(question, context)
            
            print_colored("\n=== C√ÇU TR·∫¢ L·ªúI ===", "blue")
            print(answer)
            
        except Exception as e:
            print_colored(f"‚ö†Ô∏è L·ªói: {str(e)}", "red")

if __name__ == "__main__":
    main()